# AHA-Workshop
Notes, files, etc. for a web Scraping/preservation/analysis Workshop at the American Historical Association in Denver CO 2017.

## Working Title
- Digital History and Web Scraping (a hands-on guide to automating primary-source collection and analysis from web sites and social media feeds with Ian Milligan, University of Waterloo)

## Preliminary Schedule
- **Introduction**
- **Finding Sources Online**
	- The Best Case Scenario (big red download button)
	- The Second-Best Case Scenario (an API)
	- The Third-Best Case Scenario - doing it yourself!
	- Discussion
- **Web Scraping**
	- Ethical considerations
	- Technical considerations
	- Brief tools roundtable (we won't use Command Line Tools in the class, as I think that's too difficult in a workshop - but will show their existence)
		- OutWit Hub click through
	- import.io walkthrough
	- webrecorder.io walkthrough
	- Discussion
- **Social Media Scraping**
	- Ethical considerations
	- Brief tools roundtable (i.e. twarc)
	- Grabbing twitter.com vs the API (introduction to APIs)
	- Documenting the Now walkthrough
	- Discussion
- **Preservation**
	- Where to store research data?
		- Sustainable file formats
		- Institutional repositories (i.e. Dataverse), Zenodo (CERN) 
		- Zenodo walkthrough
	- Storing code
		- GitHub - i.e. rather than just saving it
		- link to Programming Historian
	- links to other resources
	- Discussion
- **Analysis**
	- Now you have data - what to do with it?
	- Introduction to Voyant Tools
	- Introduction to *Programming Historian*
	- Walkthrough a few other tools
	- Discussion

## For Me To Do
- Zenodo walkthrough CHECK
- Set up AWS machine for DocNow TO DO IN NOVEMBER
- Think of a good walkthrough for import.io - set up a few weeks beforehand to show people the longitudinal benefits
- Host code on GitHub